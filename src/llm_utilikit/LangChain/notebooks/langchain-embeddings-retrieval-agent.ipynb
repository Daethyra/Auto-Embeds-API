{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/Daethyra/0e3f515a41d78d89babbea00c057b8d2/langchain-embeddings-retrieval-agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXC2wBpCU9f7"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/langchain-retrieval-agent.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/docs/langchain-retrieval-agent.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhWwrfbbVGOA"
      },
      "source": [
        "#### [LangChain Handbook](https://pinecone.io/learn/langchain)\n",
        "\n",
        "# Retrieval Agents\n",
        "\n",
        "We've seen in previous chapters how powerful [retrieval augmentation](https://www.pinecone.io/learn/langchain-retrieval-augmentation/) and [conversational agents](https://www.pinecone.io/learn/langchain-agents/) can be. They become even more impressive when we begin using them together.\n",
        "\n",
        "Conversational agents can struggle with data freshness, knowledge about specific domains, or accessing internal documentation. By coupling agents with retrieval augmentation tools we no longer have these problems.\n",
        "\n",
        "One the other side, using \"naive\" retrieval augmentation without the use of an agent means we will retrieve contexts with *every* query. Again, this isn't always ideal as not every query requires access to external knowledge.\n",
        "\n",
        "Merging these methods gives us the best of both worlds. In this notebook we'll learn how to do this.\n",
        "\n",
        "[![Open full notebook](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/full-link.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/langchain/handbook/08-langchain-retrieval-agent.ipynb)\n",
        "\n",
        "To begin, we must install the prerequisite libraries that we will be using in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pva9ehKXUpU2",
        "outputId": "21af5614-b078-415d-8aa3-9efd125b4757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\dae\\.vscode\\Software\\.venv\\Lib\\site-packages\\google\\~rotobuf'.\n",
            "  You can safely remove it manually.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU \\\n",
        "    openai \\\n",
        "    \"pinecone-client[grpc]\" \\\n",
        "    pinecone-datasets \\\n",
        "    langchain \\\n",
        "    tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTgrOQziXUto"
      },
      "source": [
        "## Building the Knowledge Base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNyRsz0ZXXaq"
      },
      "source": [
        "We will download a pre-embedded dataset from `pinecone-datasets`. Allowing us to skip the embedding and preprocessing steps, if you'd rather work through those steps you can find the [full notebook here](https://github.com/pinecone-io/examples/blob/master/generation/langchain/handbook/08-langchain-retrieval-agent.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ANN_DEEP1B_d96_angular',\n",
              " 'ANN_Fashion-MNIST_d784_euclidean',\n",
              " 'ANN_GIST_d960_euclidean',\n",
              " 'ANN_GloVe_d100_angular',\n",
              " 'ANN_GloVe_d200_angular',\n",
              " 'ANN_GloVe_d25_angular',\n",
              " 'ANN_GloVe_d50_angular',\n",
              " 'ANN_LastFM_d64_angular',\n",
              " 'ANN_MNIST_d784_euclidean',\n",
              " 'ANN_NYTimes_d256_angular',\n",
              " 'ANN_SIFT1M_d128_euclidean',\n",
              " 'amazon_toys_quora_all-MiniLM-L6-bm25',\n",
              " 'it-threat-data-test',\n",
              " 'it-threat-data-train',\n",
              " 'langchain-python-docs-text-embedding-ada-002',\n",
              " 'movielens-user-ratings',\n",
              " 'msmarco-v1-bm25-allMiniLML6V2',\n",
              " 'quora_all-MiniLM-L6-bm25-100K',\n",
              " 'quora_all-MiniLM-L6-bm25',\n",
              " 'quora_all-MiniLM-L6-v2_Splade-100K',\n",
              " 'quora_all-MiniLM-L6-v2_Splade',\n",
              " 'squad-text-embedding-ada-002',\n",
              " 'wikipedia-simple-text-embedding-ada-002-100K',\n",
              " 'wikipedia-simple-text-embedding-ada-002',\n",
              " 'youtube-transcripts-text-embedding-ada-002']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pinecone_datasets import load_dataset, list_datasets\n",
        "\n",
        "# Check available datasets\n",
        "list_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "laSDMjqQXuj-",
        "outputId": "dfd8f0b5-5043-4802-fd81-78ac245f16e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "_request non-retriable exception: Invalid bucket name: 'pinecone-datasets-dev\\squad-text-embedding-ada-002', 400\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\retry.py\", line 123, in retry_request\n",
            "    return await func(*args, **kwargs)\n",
            "  File \"c:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\core.py\", line 430, in _request\n",
            "    validate_response(status, contents, path, args)\n",
            "  File \"c:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\retry.py\", line 110, in validate_response\n",
            "    raise HttpError(error)\n",
            "gcsfs.retry.HttpError: Invalid bucket name: 'pinecone-datasets-dev\\squad-text-embedding-ada-002', 400\n"
          ]
        },
        {
          "ename": "HttpError",
          "evalue": "Invalid bucket name: 'pinecone-datasets-dev\\squad-text-embedding-ada-002', 400",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msquad-text-embedding-ada-002\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m dataset\u001b[38;5;241m.\u001b[39mhead()\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\pinecone_datasets\\public.py:59\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(dataset_id, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in catalog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39mfrom_catalog(dataset_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\pinecone_datasets\\dataset.py:112\u001b[0m, in \u001b[0;36mDataset.from_catalog\u001b[1;34m(cls, dataset_id, catalog_base_path, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m catalog_base_path \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    107\u001b[0m     catalog_base_path\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m catalog_base_path\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASETS_CATALOG_BASEPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, cfg\u001b[38;5;241m.\u001b[39mStorage\u001b[38;5;241m.\u001b[39mendpoint)\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    111\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(catalog_base_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(dataset_path\u001b[38;5;241m=\u001b[39mdataset_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\pinecone_datasets\\dataset.py:212\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, dataset_path, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs \u001b[38;5;241m=\u001b[39m get_cloud_fs(endpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_path \u001b[38;5;241m=\u001b[39m dataset_path\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset does not exist. Please check the path or dataset_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m         )\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\fsspec\\asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\fsspec\\asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\fsspec\\asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[1;34m(event, coro, result, timeout)\u001b[0m\n\u001b[0;32m     54\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m     58\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\fsspec\\asyn.py:677\u001b[0m, in \u001b[0;36mAsyncFileSystem._exists\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_exists\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 677\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info(path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\core.py:926\u001b[0m, in \u001b[0;36mGCSFileSystem._info\u001b[1;34m(self, path, generation, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m path:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    927\u001b[0m         out\u001b[38;5;241m.\u001b[39mupdate(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;66;03m# GET bucket failed, try ls; will have no metadata\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\core.py:437\u001b[0m, in \u001b[0;36mGCSFileSystem._call\u001b[1;34m(self, method, path, json_out, info_out, *args, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, path, \u001b[38;5;241m*\u001b[39margs, json_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, info_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    435\u001b[0m ):\n\u001b[0;32m    436\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 437\u001b[0m     status, headers, info, contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    438\u001b[0m         method, path, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    439\u001b[0m     )\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m json_out:\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(contents)\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\decorator.py:221\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    220\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\retry.py:158\u001b[0m, in \u001b[0;36mretry_request\u001b[1;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    157\u001b[0m logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m non-retriable exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\retry.py:123\u001b[0m, in \u001b[0;36mretry_request\u001b[1;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (retry \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m32\u001b[39m))\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m     HttpError,\n\u001b[0;32m    126\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m     aiohttp\u001b[38;5;241m.\u001b[39mclient_exceptions\u001b[38;5;241m.\u001b[39mClientError,\n\u001b[0;32m    130\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(e, HttpError)\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequester pays\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m    135\u001b[0m     ):\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\core.py:430\u001b[0m, in \u001b[0;36mGCSFileSystem._request\u001b[1;34m(self, method, path, headers, json, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m info \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrequest_info  \u001b[38;5;66;03m# for debug only\u001b[39;00m\n\u001b[0;32m    428\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m r\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 430\u001b[0m \u001b[43mvalidate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status, headers, info, contents\n",
            "File \u001b[1;32mc:\\Users\\dae\\.vscode\\Software\\.venv\\lib\\site-packages\\gcsfs\\retry.py:110\u001b[0m, in \u001b[0;36mvalidate_response\u001b[1;34m(status, content, path, args)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBad Request: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(error)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m: status, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: msg})  \u001b[38;5;66;03m# text-like\u001b[39;00m\n",
            "\u001b[1;31mHttpError\u001b[0m: Invalid bucket name: 'pinecone-datasets-dev\\squad-text-embedding-ada-002', 400"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"squad-text-embedding-ada-002\")\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Q16wRH9SmO",
        "outputId": "fdf2947f-a270-4417-a02b-057e62356dfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18891"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3-Plec39SmO"
      },
      "source": [
        "We'll format the dataset ready for upsert and reduce what we use to a subset of the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4CW5mNi89SmO",
        "outputId": "b7485e0d-1aa6-4f2b-840e-fdef19d58ffc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ae493f02-d341-44ae-b022-ef7c62f7ae4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>values</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "      <td>[-0.010262451963272523, 0.02222637996192584, -...</td>\n",
              "      <td>{'text': 'Architecturally, the school has a Ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5733bf84d058e614000b61be</td>\n",
              "      <td>[-0.009786712423983223, -0.013988726438873078,...</td>\n",
              "      <td>{'text': 'As at most other universities, Notre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5733bed24776f41900661188</td>\n",
              "      <td>[0.013343917696606181, -0.0007001232846109822,...</td>\n",
              "      <td>{'text': 'The university is the major seat of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5733a6424776f41900660f51</td>\n",
              "      <td>[-0.0085222901071539, 0.004399558219521822, -0...</td>\n",
              "      <td>{'text': 'The College of Engineering was estab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5733a70c4776f41900660f64</td>\n",
              "      <td>[-0.006695996885869355, -0.02067068565761649, ...</td>\n",
              "      <td>{'text': 'All of Notre Dame's undergraduate st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae493f02-d341-44ae-b022-ef7c62f7ae4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae493f02-d341-44ae-b022-ef7c62f7ae4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae493f02-d341-44ae-b022-ef7c62f7ae4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2794b672-1cdf-41a1-8f1b-4d58ca5d2ecb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2794b672-1cdf-41a1-8f1b-4d58ca5d2ecb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2794b672-1cdf-41a1-8f1b-4d58ca5d2ecb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                         id  \\\n",
              "0  5733be284776f41900661182   \n",
              "1  5733bf84d058e614000b61be   \n",
              "2  5733bed24776f41900661188   \n",
              "3  5733a6424776f41900660f51   \n",
              "4  5733a70c4776f41900660f64   \n",
              "\n",
              "                                              values  \\\n",
              "0  [-0.010262451963272523, 0.02222637996192584, -...   \n",
              "1  [-0.009786712423983223, -0.013988726438873078,...   \n",
              "2  [0.013343917696606181, -0.0007001232846109822,...   \n",
              "3  [-0.0085222901071539, 0.004399558219521822, -0...   \n",
              "4  [-0.006695996885869355, -0.02067068565761649, ...   \n",
              "\n",
              "                                            metadata  \n",
              "0  {'text': 'Architecturally, the school has a Ca...  \n",
              "1  {'text': 'As at most other universities, Notre...  \n",
              "2  {'text': 'The university is the major seat of ...  \n",
              "3  {'text': 'The College of Engineering was estab...  \n",
              "4  {'text': 'All of Notre Dame's undergraduate st...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we drop sparse_values as they are not needed for this example\n",
        "dataset.documents.drop(['sparse_values', 'blob'], axis=1, inplace=True)\n",
        "\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2_Pt7N6Zg2X"
      },
      "source": [
        "## Vector Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQTfOTR6aBRS"
      },
      "source": [
        "Next we initialize a Pinecone vector database. For this we need a [free API key](https://app.pinecone.io/), then we create the index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3wrG-9yaJel"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "import os\n",
        "\n",
        "# Load Pinecone API key\n",
        "api_key = os.getenv('PINECONE_API_KEY') or 'api_key'\n",
        "# Set Pinecone environment. Find next to API key in console\n",
        "env = os.getenv('PINECONE_ENVIRONMENT') or \"us-central1-gcp\"\n",
        "\n",
        "pinecone.init(api_key=api_key, environment=env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgfywcQj9SmP"
      },
      "outputs": [],
      "source": [
        "index_name = 'langchain-retrieval-agent-fast'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5WT4PAN9SmP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "if index_name in pinecone.list_indexes():\n",
        "   pinecone.delete_index(index_name)\n",
        "\n",
        "# we create a new index\n",
        "pinecone.create_index(\n",
        "    name=index_name,\n",
        "    metric='dotproduct',\n",
        "    dimension=1536  # 1536 dim of text-embedding-ada-002\n",
        ")\n",
        "\n",
        "# wait for index to be initialized\n",
        "while not pinecone.describe_index(index_name).status['ready']:\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiSWrAQ5aRco"
      },
      "source": [
        "Then connect to the index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfsfuFmqaS4G",
        "outputId": "45f17443-b87a-4682-ab44-6cfd6efdc46c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index = pinecone.GRPCIndex(index_name)\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbDTrvvm9SmP"
      },
      "source": [
        "We should see that the new Pinecone index has a `total_vector_count` of `0`, as we haven't added any vectors yet.\n",
        "\n",
        "Now we upsert the data to Pinecone:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "d7b2791e5f3d4c68b02da4123f715a72",
            "e4e2a2e10c684ac7bbf102bad235464f",
            "5290c01d786b4baf8b5e9adfe1a5befe",
            "f073c54fdece48c0817f21f0970621d9",
            "c593df22c7294a078a8d036d10e1c117",
            "2a15af3253884c7cb97c6c6f3dd21e3f",
            "bb3e80cb30214f6b80c4316606761d34",
            "1a90f0bf4c8e4aabb8e346c3d9cfdff6",
            "6e332262dd2944a68e3415bc827f1407",
            "ded11ea7cc6b4c8aa6acbe8d03a6f742",
            "bd0b82bd40b0418a8e326bec7e1cfe9e",
            "2868c074bd55491a92000c7cd363ce6b",
            "be04454d283147d79e353c1ab24b8573",
            "89c1ae7c90004a6bae1e5aeedb19fa8c",
            "b22dd946e0ac4a0abfb27efcf811c790",
            "dd464906d8ab4900916b35dd3e779d46",
            "4b2dd63f4b5e4a40ab5ec52826cc5bb3",
            "87258691c1e041219045522dcf52bc52",
            "9f125e0287ed46ebba34a0d26cdfb8cc",
            "795dabbc25bb426c8756a36b5778f572",
            "d9dd4543607840bfb4e813e801549c66",
            "7e51d478a2e14ff09853d93c102ff40f"
          ]
        },
        "id": "AhDcbRGTaWPi",
        "outputId": "14b0b058-fa02-4078-83b9-7c3067edf613"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7b2791e5f3d4c68b02da4123f715a72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sending upsert requests:   0%|          | 0/18891 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2868c074bd55491a92000c7cd363ce6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "collecting async responses:   0%|          | 0/148 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "upserted_count: 18891"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.upsert_from_dataframe(dataset.documents, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDUnLdy1b7G1"
      },
      "source": [
        "We've indexed everything, now we can check the number of vectors in our index like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiccGZKAb_Qo",
        "outputId": "c0e1ad44-f0a2-48b3-b1b6-0a1f35c83102"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.1,\n",
              " 'namespaces': {'': {'vector_count': 18891}},\n",
              " 'total_vector_count': 18891}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-3oolT5cCR8"
      },
      "source": [
        "## Creating a Vector Store and Querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-og9Vt_-9SmQ"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY') or 'sk-'\n",
        "model_name = 'text-embedding-ada-002'\n",
        "\n",
        "embed = OpenAIEmbeddings(\n",
        "    model=model_name,\n",
        "    openai_api_key=openai_api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcZ12U06cCH5"
      },
      "source": [
        "Now that we've build our index we can switch back over to LangChain. We start by initializing a vector store using the same index we just built. We do that like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MBJ477-cFNw"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "text_field = \"text\"\n",
        "\n",
        "# switch back to normal index for langchain\n",
        "index = pinecone.Index(index_name)\n",
        "\n",
        "vectorstore = Pinecone(\n",
        "    index, embed.embed_query, text_field\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K3xRthWcXzW"
      },
      "source": [
        "As in previous examples, we can use the `similarity_search` method to do a pure semantic search (without the generation component)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uITMZtzschJF",
        "outputId": "e6fce934-0927-4710-b60e-33cb9b2018b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Episcopalians and Presbyterians, as well as other WASPs, tend to be considerably wealthier and better educated (having graduate and post-graduate degrees per capita) than most other religious groups in United States, and are disproportionately represented in the upper reaches of American business, law and politics, especially the Republican Party. Numbers of the most wealthy and affluent American families as the Vanderbilts and the Astors, Rockefeller, Du Pont, Roosevelt, Forbes, Whitneys, the Morgans and Harrimans are Mainline Protestant families.', metadata={'title': 'Protestantism'}),\n",
              " Document(page_content='Yale has had many financial supporters, but some stand out by the magnitude or timeliness of their contributions. Among those who have made large donations commemorated at the university are: Elihu Yale; Jeremiah Dummer; the Harkness family (Edward, Anna, and William); the Beinecke family (Edwin, Frederick, and Walter); John William Sterling; Payne Whitney; Joseph E. Sheffield, Paul Mellon, Charles B. G. Murphy and William K. Lanman. The Yale Class of 1954, led by Richard Gilder, donated $70 million in commemoration of their 50th reunion. Charles B. Johnson, a 1954 graduate of Yale College, pledged a $250 million gift in 2013 to support of the construction of two new residential colleges.', metadata={'title': 'Yale_University'}),\n",
              " Document(page_content='During a panel discussion at Harvard University\\'s reunion for African American alumni during the 2003–04 academic year, two prominent black professors at the institution—Lani Guinier and Henry Louis Gates—pointed out an unintended effect of affirmative action policies at Harvard. They stated that only about a third of black Harvard undergraduates were from families in which all four grandparents were born into the African American community. The majority of black students at Harvard were Caribbean and African immigrants or their children, with some others the mixed-race children of biracial couples. One Harvard student, born in the South Bronx to a black family whose ancestors have been in the United States for multiple generations, said that there were so few Harvard students from the historic African American community that they took to calling themselves \"the descendants\" (i.e., descendants of American slaves). The reasons for this underrepresentation of historic African Americans, and possible remedies, remain a subject of debate.', metadata={'title': 'Affirmative_action_in_the_United_States'}),\n",
              " Document(page_content='During the Gilded Age, there was substantial growth in population in the United States and extravagant displays of wealth and excess of America\\'s upper-class during the post-Civil War and post-Reconstruction era, in the late 19th century. The wealth polarization derived primarily from industrial and population expansion. The businessmen of the Second Industrial Revolution created industrial towns and cities in the Northeast with new factories, and contributed to the creation of an ethnically diverse industrial working class which produced the wealth owned by rising super-rich industrialists and financiers called the \"robber barons\". An example is the company of John D. Rockefeller, who was an important figure in shaping the new oil industry. Using highly effective tactics and aggressive practices, later widely criticized, Standard Oil absorbed or destroyed most of its competition.', metadata={'title': 'Modern_history'}),\n",
              " Document(page_content='In the United States, two of the wealthiest nonprofit organizations are the Bill and Melinda Gates Foundation, which has an endowment of US$38 billion, and the Howard Hughes Medical Institute originally funded by Hughes Aircraft prior to divestiture, which has an endowment of approximately $14.8 billion. Outside the United States, another large NPO is the British Wellcome Trust, which is a \"charity\" by British usage. See: List of wealthiest foundations. Note that this assessment excludes universities, at least a few of which have assets in the tens of billions of dollars. For example; List of U.S. colleges and universities by endowment.', metadata={'title': 'Nonprofit_organization'})]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What universities had the most intergenerational wealth?\"\n",
        "\n",
        "vectorstore.similarity_search(\n",
        "    query,  # our search query\n",
        "    k=5  # return 3 most relevant docs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zGF6YsgczqT"
      },
      "source": [
        "Looks like we're getting good results. Let's take a look at how we can begin integrating this into a conversational agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFsIOm73dcOI"
      },
      "source": [
        "## Initializing the Conversational Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMv6TXWkdfNR"
      },
      "source": [
        "Our conversational agent needs a Chat LLM, conversational memory, and a `RetrievalQA` chain to initialize. We create these using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMRs9Klic5-Y"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# chat completion llm\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=openai_api_key,\n",
        "    model_name='gpt-3.5-turbo',\n",
        "    temperature=0.0\n",
        ")\n",
        "# conversational memory\n",
        "conversational_memory = ConversationBufferWindowMemory(\n",
        "    memory_key='chat_history',\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")\n",
        "# retrieval qa chain\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ySfWyZLdboX"
      },
      "source": [
        "Using these we can generate an answer using the `run` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "LaYSq0V-dxHw",
        "outputId": "1f7b2862-6dd4-450e-b2a5-3bb23a3a9530"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Based on the provided context, Yale University is mentioned as having received significant donations from wealthy individuals and families, such as Elihu Yale, the Harkness family, the Beinecke family, John William Sterling, Payne Whitney, Joseph E. Sheffield, Paul Mellon, Charles B. G. Murphy, William K. Lanman, and the Yale Class of 1954. These donations suggest a strong presence of intergenerational wealth at Yale University. However, it is important to note that this information does not provide a comprehensive ranking of universities based on intergenerational wealth.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa.run(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtSXR5RXdyU0"
      },
      "source": [
        "But this isn't yet ready for our conversational agent. For that we need to convert this retrieval chain into a tool. We do that like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwCYrS4duqBW"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name='Knowledge Base',\n",
        "        func=qa.run,\n",
        "        description=(\n",
        "            'use this tool when answering general knowledge queries to get '\n",
        "            'more information about the topic'\n",
        "        )\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXi_0ipTvM_l"
      },
      "source": [
        "Now we can initialize the agent like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaKTzPUEvOoy"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "agent = initialize_agent(\n",
        "    agent='chat-conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate',\n",
        "    memory=conversational_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbXl-AzVvszB"
      },
      "source": [
        "With that our retrieval augmented conversational agent is ready and we can begin using it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlxUBWKcvzeP"
      },
      "source": [
        "### Using the Conversational Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZapCP4Pv2kz"
      },
      "source": [
        "To make queries we simply call the `agent` directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJoAhy76vzAB",
        "outputId": "62d6f4b2-42c1-485f-d9fc-51866f2488b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Knowledge Base\",\n",
            "    \"action_input\": \"Universities with the most intergenerational wealth\"\n",
            "}\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mI don't have specific information on universities with the most intergenerational wealth. However, some universities in the United States have significant endowments, which can contribute to their overall wealth. Examples of universities with large endowments include Harvard University, Stanford University, and Princeton University.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Some universities in the United States with large endowments include Harvard University, Stanford University, and Princeton University.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What universities had the most intergenerational wealth?',\n",
              " 'chat_history': [],\n",
              " 'output': 'Some universities in the United States with large endowments include Harvard University, Stanford University, and Princeton University.'}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcMqa9Va2hU6"
      },
      "source": [
        "Looks great, now what if we ask it a non-general knowledge question?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85vipqC02deV",
        "outputId": "96dfbebf-82ba-420b-ee4c-de1abea670c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"The product of 2 multiplied by 7 is 14.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'what is 2 * 7?',\n",
              " 'chat_history': [HumanMessage(content='What universities had the most intergenerational wealth?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Some universities in the United States with large endowments include Harvard University, Stanford University, and Princeton University.', additional_kwargs={}, example=False)],\n",
              " 'output': 'The product of 2 multiplied by 7 is 14.'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"what is 2 * 7?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR_b0IN32rQ9"
      },
      "source": [
        "Perfect, the agent is able to recognize that it doesn't need to refer to it's general knowledge tool for that question. Let's try some more questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQeicHTj2pmY",
        "outputId": "af5b61d9-4d7d-45fe-c561-521256246acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Knowledge Base\",\n",
            "    \"action_input\": \"legacy admissions\"\n",
            "}\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mLegacy admissions refer to the practice of giving preferential treatment to applicants who have family members who attended the university in question. This means that if a student's parent, grandparent, or sibling attended the university, they may have a higher chance of being admitted compared to other applicants with similar qualifications. Legacy admissions are one of the factors that can be taken into account in the holistic admissions process used by some universities in the United States.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Legacy admissions refer to the practice of giving preferential treatment to applicants who have family members who attended the university in question. This means that if a student's parent, grandparent, or sibling attended the university, they may have a higher chance of being admitted compared to other applicants with similar qualifications. Legacy admissions are one of the factors that can be taken into account in the holistic admissions process used by some universities in the United States.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'can you tell me some facts about legacy admissions?',\n",
              " 'chat_history': [HumanMessage(content='What universities had the most intergenerational wealth?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Some universities in the United States with large endowments include Harvard University, Stanford University, and Princeton University.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='what is 2 * 7?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='The product of 2 multiplied by 7 is 14.', additional_kwargs={}, example=False)],\n",
              " 'output': \"Legacy admissions refer to the practice of giving preferential treatment to applicants who have family members who attended the university in question. This means that if a student's parent, grandparent, or sibling attended the university, they may have a higher chance of being admitted compared to other applicants with similar qualifications. Legacy admissions are one of the factors that can be taken into account in the holistic admissions process used by some universities in the United States.\"}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"can you tell me some facts about legacy admissions?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G93vLXso3B5Z",
        "outputId": "9a955254-4ec9-4c40-d65d-c822e963cdf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Knowledge Base\",\n",
            "    \"action_input\": \"Legacy admissions and their impact on the playing field in college admissions\"\n",
            "}\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mLegacy admissions refer to the practice of giving preferential treatment to applicants who have family members, usually parents or grandparents, who attended the university in question. This practice is controversial because it can perpetuate social and economic advantages for certain groups of people, particularly those from wealthier backgrounds. \n",
            "\n",
            "Legacy admissions can have an impact on the playing field in college admissions by potentially disadvantaging applicants from underrepresented or disadvantaged backgrounds. By giving preference to legacy applicants, universities may be prioritizing the continuation of a privileged class rather than promoting diversity and equal opportunity. This can create a system where certain groups have a higher likelihood of gaining admission based on their family connections rather than their own merits.\n",
            "\n",
            "However, it is important to note that the impact of legacy admissions on the playing field is just one aspect of the broader debate on affirmative action and racial preferences in college admissions. The issue is complex and involves considerations of diversity, merit, and the mission of universities.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Legacy admissions can have a negative impact on the playing field in college admissions by potentially disadvantaging applicants from underrepresented or disadvantaged backgrounds. By giving preferential treatment to legacy applicants, universities may prioritize the continuation of a privileged class rather than promoting diversity and equal opportunity.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Teach a class of 7th graders how legacy admissions ruin the playing field.',\n",
              " 'chat_history': [HumanMessage(content='What universities had the most intergenerational wealth?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='Some universities in the United States with large endowments include Harvard University, Stanford University, and Princeton University.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='what is 2 * 7?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='The product of 2 multiplied by 7 is 14.', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='can you tell me some facts about legacy admissions?', additional_kwargs={}, example=False),\n",
              "  AIMessage(content=\"Legacy admissions refer to the practice of giving preferential treatment to applicants who have family members who attended the university in question. This means that if a student's parent, grandparent, or sibling attended the university, they may have a higher chance of being admitted compared to other applicants with similar qualifications. Legacy admissions are one of the factors that can be taken into account in the holistic admissions process used by some universities in the United States.\", additional_kwargs={}, example=False)],\n",
              " 'output': 'Legacy admissions can have a negative impact on the playing field in college admissions by potentially disadvantaging applicants from underrepresented or disadvantaged backgrounds. By giving preferential treatment to legacy applicants, universities may prioritize the continuation of a privileged class rather than promoting diversity and equal opportunity.'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Teach a class of 7th graders how legacy admissions ruin the playing field.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWivmw9F3bCw"
      },
      "source": [
        "Looks great! We're also able to ask questions that refer to previous interactions in the conversation and the agent is able to refer to the conversation history to as a source of information.\n",
        "\n",
        "That's all for this example of building a retrieval augmented conversational agent with OpenAI and Pinecone (the OP stack) and LangChain.\n",
        "\n",
        "Once finished, we delete the Pinecone index to save resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa1whr8V3Wfm"
      },
      "outputs": [],
      "source": [
        "pinecone.delete_index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykg5TYA033yR"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bhWwrfbbVGOA"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a90f0bf4c8e4aabb8e346c3d9cfdff6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2868c074bd55491a92000c7cd363ce6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be04454d283147d79e353c1ab24b8573",
              "IPY_MODEL_89c1ae7c90004a6bae1e5aeedb19fa8c",
              "IPY_MODEL_b22dd946e0ac4a0abfb27efcf811c790"
            ],
            "layout": "IPY_MODEL_dd464906d8ab4900916b35dd3e779d46"
          }
        },
        "2a15af3253884c7cb97c6c6f3dd21e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2dd63f4b5e4a40ab5ec52826cc5bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5290c01d786b4baf8b5e9adfe1a5befe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a90f0bf4c8e4aabb8e346c3d9cfdff6",
            "max": 18891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e332262dd2944a68e3415bc827f1407",
            "value": 18891
          }
        },
        "6e332262dd2944a68e3415bc827f1407": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "795dabbc25bb426c8756a36b5778f572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e51d478a2e14ff09853d93c102ff40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87258691c1e041219045522dcf52bc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89c1ae7c90004a6bae1e5aeedb19fa8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f125e0287ed46ebba34a0d26cdfb8cc",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_795dabbc25bb426c8756a36b5778f572",
            "value": 148
          }
        },
        "9f125e0287ed46ebba34a0d26cdfb8cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b22dd946e0ac4a0abfb27efcf811c790": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9dd4543607840bfb4e813e801549c66",
            "placeholder": "​",
            "style": "IPY_MODEL_7e51d478a2e14ff09853d93c102ff40f",
            "value": " 148/148 [00:00&lt;00:00, 1274.85it/s]"
          }
        },
        "bb3e80cb30214f6b80c4316606761d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd0b82bd40b0418a8e326bec7e1cfe9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be04454d283147d79e353c1ab24b8573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2dd63f4b5e4a40ab5ec52826cc5bb3",
            "placeholder": "​",
            "style": "IPY_MODEL_87258691c1e041219045522dcf52bc52",
            "value": "collecting async responses: 100%"
          }
        },
        "c593df22c7294a078a8d036d10e1c117": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b2791e5f3d4c68b02da4123f715a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4e2a2e10c684ac7bbf102bad235464f",
              "IPY_MODEL_5290c01d786b4baf8b5e9adfe1a5befe",
              "IPY_MODEL_f073c54fdece48c0817f21f0970621d9"
            ],
            "layout": "IPY_MODEL_c593df22c7294a078a8d036d10e1c117"
          }
        },
        "d9dd4543607840bfb4e813e801549c66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd464906d8ab4900916b35dd3e779d46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ded11ea7cc6b4c8aa6acbe8d03a6f742": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e2a2e10c684ac7bbf102bad235464f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a15af3253884c7cb97c6c6f3dd21e3f",
            "placeholder": "​",
            "style": "IPY_MODEL_bb3e80cb30214f6b80c4316606761d34",
            "value": "sending upsert requests: 100%"
          }
        },
        "f073c54fdece48c0817f21f0970621d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ded11ea7cc6b4c8aa6acbe8d03a6f742",
            "placeholder": "​",
            "style": "IPY_MODEL_bd0b82bd40b0418a8e326bec7e1cfe9e",
            "value": " 18891/18891 [00:05&lt;00:00, 4043.05it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
