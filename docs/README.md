## Document assortment

### Continued Education

Reading meant to give context of the AI's "thought" process' limitations.

Highlights:
1. Lost In the Middle: How Language Models Use Long Contexts
  - Abstract: While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval.
2. "Needle In A Haystack" Analysis: Pressure Testing GPT-4 & Claude 2.1's Long Context Retrieval Accuracy
  - An exported email from Greg Kramradt's mailing list. He personally pressure tested these models with the intention of helping others make smarter decisions when it comes to retrieval.

### Custom-GPT - Uploadable Knowledge Base

Files currently in use for my CustomGPTs.

### Jupyter Notebooks

A collection of notebooks that teach learners how to build retrieval augmented generation (RAG) AI. RAG helps solve a data-freshness problem that all LLMs inherently have.