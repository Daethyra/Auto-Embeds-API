{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/Daethyra/d0cbebe9e9cac928f1905f9fca975873/copy-of-langsmith-walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a4596ea-a631-416d-a2a4-3577c140493d",
      "metadata": {
        "tags": [],
        "id": "1a4596ea-a631-416d-a2a4-3577c140493d"
      },
      "source": [
        "# LangSmith Walkthrough\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/langsmith/walkthrough.ipynb)\n",
        "\n",
        "LangChain makes it easy to prototype LLM applications and Agents. However, delivering LLM applications to production can be deceptively difficult. You will likely have to heavily customize and iterate on your prompts, chains, and other components to create a high-quality product.\n",
        "\n",
        "To aid in this process, we've launched LangSmith, a unified platform for debugging, testing, and monitoring your LLM applications.\n",
        "\n",
        "When might this come in handy? You may find it useful when you want to:\n",
        "\n",
        "- Quickly debug a new chain, agent, or set of tools\n",
        "- Visualize how components (chains, llms, retrievers, etc.) relate and are used\n",
        "- Evaluate different prompts and LLMs for a single component\n",
        "- Run a given chain several times over a dataset to ensure it consistently meets a quality bar\n",
        "- Capture usage traces and using LLMs or analytics pipelines to generate insights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "138fbb8f-960d-4d26-9dd5-6d6acab3ee55",
      "metadata": {
        "id": "138fbb8f-960d-4d26-9dd5-6d6acab3ee55"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "**[Create a LangSmith account](https://smith.langchain.com/) and create an API key (see bottom left corner). Familiarize yourself with the platform by looking through the [docs](https://docs.smith.langchain.com/)**\n",
        "\n",
        "Note LangSmith is in closed beta; we're in the process of rolling it out to more users. However, you can fill out the form on the website for expedited access.\n",
        "\n",
        "Now, let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d77d064-41b4-41fb-82e6-2d16461269ec",
      "metadata": {
        "tags": [],
        "id": "2d77d064-41b4-41fb-82e6-2d16461269ec"
      },
      "source": [
        "## Log runs to LangSmith\n",
        "\n",
        "First, configure your environment variables to tell LangChain to log traces. This is done by setting the `LANGCHAIN_TRACING_V2` environment variable to true.\n",
        "You can tell LangChain which project to log to by setting the `LANGCHAIN_PROJECT` environment variable (if this isn't set, runs will be logged to the `default` project). This will automatically create the project for you if it doesn't exist. You must also set the `LANGCHAIN_ENDPOINT` and `LANGCHAIN_API_KEY` environment variables.\n",
        "\n",
        "For more information on other ways to set up tracing, please reference the [LangSmith documentation](https://docs.smith.langchain.com/docs/).\n",
        "\n",
        "**NOTE:** You must also set your `OPENAI_API_KEY` environment variables in order to run the following tutorial.\n",
        "\n",
        "**NOTE:** You can only access an API key when you first create it. Keep it somewhere safe.\n",
        "\n",
        "**NOTE:** You can also use a context manager in python to log traces using\n",
        "```python\n",
        "from langchain.callbacks.manager import tracing_v2_enabled\n",
        "\n",
        "with tracing_v2_enabled(project_name=\"My Project\"):\n",
        "    agent.run(\"How many people live in canada as of 2023?\")\n",
        "```\n",
        "\n",
        "However, in this example, we will use environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e4780363-f05a-4649-8b1a-9b449f960ce4",
      "metadata": {
        "id": "e4780363-f05a-4649-8b1a-9b449f960ce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6629ef72-3db8-498f-9544-517b6632f66c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -Uq langchain langsmith langchainhub\n",
        "%pip install -Uq openai tiktoken pandas duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "904db9a5-f387-4a57-914c-c8af8d39e249",
      "metadata": {
        "tags": [],
        "id": "904db9a5-f387-4a57-914c-c8af8d39e249"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from uuid import uuid4\n",
        "\n",
        "unique_id = uuid4().hex[0:8]\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__f91f3729227e4303bba5e431287ffc34\"  # Update to your API key\n",
        "\n",
        "# Used by the agent in this tutorial\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee7f34b-b65c-4e09-ad52-e3ace78d0221",
      "metadata": {
        "tags": [],
        "id": "8ee7f34b-b65c-4e09-ad52-e3ace78d0221"
      },
      "source": [
        "Create the langsmith client to interact with the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "510b5ca0",
      "metadata": {
        "tags": [],
        "id": "510b5ca0"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca27fa11-ddce-4af0-971e-c5c37d5b92ef",
      "metadata": {
        "id": "ca27fa11-ddce-4af0-971e-c5c37d5b92ef"
      },
      "source": [
        "Create a LangChain component and log runs to the platform. In this example, we will create a ReAct-style agent with access to a general search tool (DuckDuckGo). The agent's prompt can be viewed in the [Hub here](https://smith.langchain.com/hub/wfh/langsmith-agent-prompt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a0fbfbba-3c82-4298-a312-9cec016d9d2e",
      "metadata": {
        "id": "a0fbfbba-3c82-4298-a312-9cec016d9d2e"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "# Fetches the latest version of this prompt\n",
        "prompt = hub.pull(\"wfh/langsmith-agent-prompt:latest\")\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo-1106\",\n",
        "    temperature=0.25,\n",
        ")\n",
        "\n",
        "tools = [\n",
        "    DuckDuckGoSearchResults(\n",
        "        name=\"duck_duck_go\"\n",
        "    ),  # General internet search using DuckDuckGo\n",
        "]\n",
        "\n",
        "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
        "\n",
        "runnable_agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        "    | OpenAIFunctionsAgentOutputParser()\n",
        ")\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=runnable_agent, tools=tools, handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cab51e1e-8270-452c-ba22-22b5b5951899",
      "metadata": {
        "id": "cab51e1e-8270-452c-ba22-22b5b5951899"
      },
      "source": [
        "We are running the agent concurrently on multiple inputs to reduce latency. Runs get logged to LangSmith in the background so execution latency is unaffected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "19537902-b95c-4390-80a4-f6c9a937081e",
      "metadata": {
        "tags": [],
        "id": "19537902-b95c-4390-80a4-f6c9a937081e"
      },
      "outputs": [],
      "source": [
        "inputs = [\n",
        "    \"What is LangChain?\",\n",
        "    \"What's LangSmith?\",\n",
        "    \"When was Llama-v2 released?\",\n",
        "    \"What is the langsmith cookbook?\",\n",
        "    \"When did langchain first announce the hub?\",\n",
        "]\n",
        "\n",
        "results = agent_executor.batch([{\"input\": x} for x in inputs], return_exceptions=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9a6a764c-5d7a-4de7-a916-3ecc987d5bb6",
      "metadata": {
        "id": "9a6a764c-5d7a-4de7-a916-3ecc987d5bb6",
        "outputId": "f928b4ff-0fff-4840-caab-bbcaddbb73cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[duckduckgo_search.exceptions.RateLimitException('_get_url() https://links.duckduckgo.com/d.js'),\n",
              " duckduckgo_search.exceptions.RateLimitException('_get_url() https://links.duckduckgo.com/d.js'),\n",
              " duckduckgo_search.exceptions.RateLimitException('_get_url() https://links.duckduckgo.com/d.js'),\n",
              " {'input': 'What is the langsmith cookbook?',\n",
              "  'output': 'The LangSmith Cookbook is a collection of recipes meant to complement the LangSmith Documentation by showing common use cases and tactics within \"end-to-end\" examples. LangSmith is a platform that helps with debugging, testing, evaluating, and monitoring LLM (Language Model) applications. It works in tandem with LangChain and provides tools for tracing and debugging for LLMs. You can find more information about it on GitHub and other platforms.'},\n",
              " duckduckgo_search.exceptions.RateLimitException('_get_url() https://links.duckduckgo.com/d.js')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "results[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9decb964-be07-4b6c-9802-9825c8be7b64",
      "metadata": {
        "id": "9decb964-be07-4b6c-9802-9825c8be7b64"
      },
      "source": [
        "Assuming you've successfully set up your environment, your agent traces should show up in the `Projects` section in the [app](https://smith.langchain.com/). Congrats!\n",
        "\n",
        "![Initial Runs](https://github.com/langchain-ai/langchain/blob/master/docs/docs/langsmith/img/log_traces.png?raw=1)\n",
        "\n",
        "It looks like the agent isn't effectively using the tools though. Let's evaluate this so we have a baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c43c311-4e09-4d57-9ef3-13afb96ff430",
      "metadata": {
        "id": "6c43c311-4e09-4d57-9ef3-13afb96ff430"
      },
      "source": [
        "## Evaluate Agent\n",
        "\n",
        "In addition to logging runs, LangSmith also allows you to test and evaluate your LLM applications.\n",
        "\n",
        "In this section, you will leverage LangSmith to create a benchmark dataset and run AI-assisted evaluators on an agent. You will do so in a few steps:\n",
        "\n",
        "1. Create a dataset\n",
        "2. Initialize a new agent to benchmark\n",
        "3. Configure evaluators to grade an agent's output\n",
        "4. Run the agent over the dataset and evaluate the results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beab1a29-b79d-4a99-b5b1-0870c2d772b1",
      "metadata": {
        "id": "beab1a29-b79d-4a99-b5b1-0870c2d772b1"
      },
      "source": [
        "### 1. Create a LangSmith dataset\n",
        "\n",
        "Below, we use the LangSmith client to create a dataset from the input questions from above and a list labels. You will use these later to measure performance for a new agent. A dataset is a collection of examples, which are nothing more than input-output pairs you can use as test cases to your application.\n",
        "\n",
        "For more information on datasets, including how to create them from CSVs or other files or how to create them in the platform, please refer to the [LangSmith documentation](https://docs.smith.langchain.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "43fd40b2-3f02-4e51-9343-705aafe90a36",
      "metadata": {
        "id": "43fd40b2-3f02-4e51-9343-705aafe90a36"
      },
      "outputs": [],
      "source": [
        "outputs = [\n",
        "    \"LangChain is an open-source framework for building applications using large language models. It is also the name of the company building LangSmith.\",\n",
        "    \"LangSmith is a unified platform for debugging, testing, and monitoring language model applications and agents powered by LangChain\",\n",
        "    \"July 18, 2023\",\n",
        "    \"The langsmith cookbook is a github repository containing detailed examples of how to use LangSmith to debug, evaluate, and monitor large language model-powered applications.\",\n",
        "    \"September 5, 2023\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "17580c4b-bd04-4dde-9d21-9d4edd25b00d",
      "metadata": {
        "tags": [],
        "id": "17580c4b-bd04-4dde-9d21-9d4edd25b00d"
      },
      "outputs": [],
      "source": [
        "dataset_name = f\"agent-qa-{unique_id}\"\n",
        "\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name,\n",
        "    description=\"An example dataset of questions over the LangSmith documentation.\",\n",
        ")\n",
        "\n",
        "for query, answer in zip(inputs, outputs):\n",
        "    client.create_example(\n",
        "        inputs={\"input\": query}, outputs={\"output\": answer}, dataset_id=dataset.id\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8adfd29c-b258-49e5-94b4-74597a12ba16",
      "metadata": {
        "tags": [],
        "id": "8adfd29c-b258-49e5-94b4-74597a12ba16"
      },
      "source": [
        "### 2. Initialize a new agent to benchmark\n",
        "\n",
        "LangSmith lets you evaluate any LLM, chain, agent, or even a custom function. Conversational agents are stateful (they have memory); to ensure that this state isn't shared between dataset runs, we will pass in a `chain_factory` (aka a `constructor`) function to initialize for each call.\n",
        "\n",
        "In this case, we will test an agent that uses OpenAI's function calling endpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f42d8ecc-d46a-448b-a89c-04b0f6907f75",
      "metadata": {
        "tags": [],
        "id": "f42d8ecc-d46a-448b-a89c-04b0f6907f75"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, AgentType, initialize_agent, load_tools\n",
        "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "\n",
        "# Since chains can be stateful (e.g. they can have memory), we provide\n",
        "# a way to initialize a new chain for each row in the dataset. This is done\n",
        "# by passing in a factory function that returns a new chain for each row.\n",
        "def agent_factory(prompt):\n",
        "    llm_with_tools = llm.bind(\n",
        "        functions=[format_tool_to_openai_function(t) for t in tools]\n",
        "    )\n",
        "    runnable_agent = (\n",
        "        {\n",
        "            \"input\": lambda x: x[\"input\"],\n",
        "            \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
        "                x[\"intermediate_steps\"]\n",
        "            ),\n",
        "        }\n",
        "        | prompt\n",
        "        | llm_with_tools\n",
        "        | OpenAIFunctionsAgentOutputParser()\n",
        "    )\n",
        "    return AgentExecutor(agent=runnable_agent, tools=tools, handle_parsing_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cb9ef53",
      "metadata": {
        "id": "9cb9ef53"
      },
      "source": [
        "### 3. Configure evaluation\n",
        "\n",
        "Manually comparing the results of chains in the UI is effective, but it can be time consuming.\n",
        "It can be helpful to use automated metrics and AI-assisted feedback to evaluate your component's performance.\n",
        "\n",
        "Below, we will create some pre-implemented run evaluators that do the following:\n",
        "- Compare results against ground truth labels.\n",
        "- Measure semantic (dis)similarity using embedding distance\n",
        "- Evaluate 'aspects' of the agent's response in a reference-free manner using custom criteria\n",
        "\n",
        "For a longer discussion of how to select an appropriate evaluator for your use case and how to create your own\n",
        "custom evaluators, please refer to the [LangSmith documentation](https://docs.smith.langchain.com/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a25dc281",
      "metadata": {
        "tags": [],
        "id": "a25dc281"
      },
      "outputs": [],
      "source": [
        "from langchain.evaluation import EvaluatorType\n",
        "from langchain.smith import RunEvalConfig\n",
        "\n",
        "evaluation_config = RunEvalConfig(\n",
        "    # Evaluators can either be an evaluator type (e.g., \"qa\", \"criteria\", \"embedding_distance\", etc.) or a configuration for that evaluator\n",
        "    evaluators=[\n",
        "        # Measures whether a QA response is \"Correct\", based on a reference answer\n",
        "        # You can also select via the raw string \"qa\"\n",
        "        EvaluatorType.QA,\n",
        "        # Measure the embedding distance between the output and the reference answer\n",
        "        # Equivalent to: EvalConfig.EmbeddingDistance(embeddings=OpenAIEmbeddings())\n",
        "        EvaluatorType.EMBEDDING_DISTANCE,\n",
        "        # Grade whether the output satisfies the stated criteria.\n",
        "        # You can select a default one such as \"helpfulness\" or provide your own.\n",
        "        RunEvalConfig.LabeledCriteria(\"helpfulness\"),\n",
        "        # The LabeledScoreString evaluator outputs a score on a scale from 1-10.\n",
        "        # You can use default criteria or write our own rubric\n",
        "        RunEvalConfig.LabeledScoreString(\n",
        "            {\n",
        "                \"accuracy\": \"\"\"\n",
        "Score 1: The answer is completely unrelated to the reference.\n",
        "Score 3: The answer has minor relevance but does not align with the reference.\n",
        "Score 5: The answer has moderate relevance but contains inaccuracies.\n",
        "Score 7: The answer aligns with the reference but has minor errors or omissions.\n",
        "Score 10: The answer is completely accurate and aligns perfectly with the reference.\"\"\"\n",
        "            },\n",
        "            normalize_by=10,\n",
        "        ),\n",
        "    ],\n",
        "    # You can add custom StringEvaluator or RunEvaluator objects here as well, which will automatically be\n",
        "    # applied to each prediction. Check out the docs for examples.\n",
        "    custom_evaluators=[],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07885b10",
      "metadata": {
        "tags": [],
        "id": "07885b10"
      },
      "source": [
        "### 4. Run the agent and evaluators\n",
        "\n",
        "Use the [run_on_dataset](https://api.python.langchain.com/en/latest/smith/langchain.smith.evaluation.runner_utils.run_on_dataset.html#langchain.smith.evaluation.runner_utils.run_on_dataset) (or asynchronous [arun_on_dataset](https://api.python.langchain.com/en/latest/smith/langchain.smith.evaluation.runner_utils.arun_on_dataset.html#langchain.smith.evaluation.runner_utils.arun_on_dataset)) function to evaluate your model. This will:\n",
        "1. Fetch example rows from the specified dataset.\n",
        "2. Run your agent (or any custom function) on each example.\n",
        "3. Apply evaluators to the resulting run traces and corresponding reference examples to generate automated feedback.\n",
        "\n",
        "The results will be visible in the LangSmith app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "af8c8469-d70d-46d9-8fcd-517a1ccc7c4b",
      "metadata": {
        "id": "af8c8469-d70d-46d9-8fcd-517a1ccc7c4b"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "# We will test this version of the prompt\n",
        "prompt = hub.pull(\"wfh/langsmith-agent-prompt:798e7324\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3733269b-8085-4644-9d5d-baedcff13a2f",
      "metadata": {
        "tags": [],
        "id": "3733269b-8085-4644-9d5d-baedcff13a2f",
        "outputId": "bec26a4c-1dd6-4289-f7be-9591ec64d25e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'runnable-agent-test-5d466cbc-70daa046' at:\n",
            "https://smith.langchain.com/o/0f7461cf-206f-5c85-aa8d-48c6c48bafc5/datasets/febb8a4c-8d98-464b-bc92-dc897d5c9014/compare?selectedSessions=f224df5b-68ed-4649-b002-75f6b7024423\n",
            "\n",
            "View all tests for Dataset agent-qa-70daa046 at:\n",
            "https://smith.langchain.com/o/0f7461cf-206f-5c85-aa8d-48c6c48bafc5/datasets/febb8a4c-8d98-464b-bc92-dc897d5c9014\n",
            "[>                                                 ] 0/5"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:Chain failed for example 61ad4fa1-7142-492d-8108-55f08141d7d2 with inputs {'input': 'When was Llama-v2 released?'}\n",
            "Error Type: RateLimitException, Message: _get_url() https://links.duckduckgo.com/d.js\n",
            "WARNING:langchain.smith.evaluation.runner_utils:Chain failed for example 68217b90-657a-4b90-b3ef-639aa77aefea with inputs {'input': 'What is LangChain?'}\n",
            "Error Type: RateLimitException, Message: _get_url() https://links.duckduckgo.com/d.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------->                                        ] 1/5\r[------------------->                              ] 2/5"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:Chain failed for example c2564f23-cd21-4475-9236-3e1796ab0c3f with inputs {'input': 'When did langchain first announce the hub?'}\n",
            "Error Type: RateLimitException, Message: _get_url() https://links.duckduckgo.com/d.js\n",
            "WARNING:langchain.smith.evaluation.runner_utils:Chain failed for example 09f2f6cb-cd87-4b22-9e04-3db860ece291 with inputs {'input': 'What is the langsmith cookbook?'}\n",
            "Error Type: RateLimitException, Message: _get_url() https://links.duckduckgo.com/d.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[------------------------------------------------->] 5/5\n",
            " Experiment Results:\n",
            "                                               error  execution_time                                run_id  feedback.correctness  feedback.embedding_cosine_distance  feedback.helpfulness  feedback.score_string:accuracy\n",
            "count                                              4            5.00                                     5                  1.00                                1.00                  1.00                            1.00\n",
            "unique                                             4             NaN                                     5                   NaN                                 NaN                   NaN                             NaN\n",
            "top     _get_url() https://links.duckduckgo.com/d.js             NaN  43e60662-5e30-41a9-8a8e-130a1a1f624d                   NaN                                 NaN                   NaN                             NaN\n",
            "freq                                               1             NaN                                     1                   NaN                                 NaN                   NaN                             NaN\n",
            "mean                                             NaN            4.86                                   NaN                  1.00                                0.05                  1.00                            0.70\n",
            "std                                              NaN            1.02                                   NaN                   NaN                                 NaN                   NaN                             NaN\n",
            "min                                              NaN            4.24                                   NaN                  1.00                                0.05                  1.00                            0.70\n",
            "25%                                              NaN            4.27                                   NaN                  1.00                                0.05                  1.00                            0.70\n",
            "50%                                              NaN            4.49                                   NaN                  1.00                                0.05                  1.00                            0.70\n",
            "75%                                              NaN            4.62                                   NaN                  1.00                                0.05                  1.00                            0.70\n",
            "max                                              NaN            6.66                                   NaN                  1.00                                0.05                  1.00                            0.70\n"
          ]
        }
      ],
      "source": [
        "import functools\n",
        "\n",
        "from langchain.smith import (\n",
        "    arun_on_dataset,\n",
        "    run_on_dataset,\n",
        ")\n",
        "\n",
        "chain_results = run_on_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    llm_or_chain_factory=functools.partial(agent_factory, prompt=prompt),\n",
        "    evaluation=evaluation_config,\n",
        "    verbose=True,\n",
        "    client=client,\n",
        "    project_name=f\"runnable-agent-test-5d466cbc-{unique_id}\",\n",
        "    tags=[\n",
        "        \"testing-notebook\",\n",
        "        \"prompt:5d466cbc\",\n",
        "    ],  # Optional, adds a tag to the resulting chain runs\n",
        ")\n",
        "\n",
        "# Sometimes, the agent will error due to parsing issues, incompatible tool inputs, etc.\n",
        "# These are logged as warnings here and captured as errors in the tracing UI."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdacd159-eb4d-49e9-bb2a-c55322c40ed4",
      "metadata": {
        "tags": [],
        "id": "cdacd159-eb4d-49e9-bb2a-c55322c40ed4"
      },
      "source": [
        "### Review the test results\n",
        "\n",
        "You can review the test results tracing UI below by clicking the URL in the output above or navigating to the \"Testing & Datasets\" page in LangSmith  **\"agent-qa-{unique_id}\"** dataset.\n",
        "\n",
        "![test results](https://github.com/langchain-ai/langchain/blob/master/docs/docs/langsmith/img/test_results.png?raw=1)\n",
        "\n",
        "This will show the new runs and the feedback logged from the selected evaluators. You can also explore a summary of the results in tabular format below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9da60638-5be8-4b5f-a721-2c6627aeaf0c",
      "metadata": {
        "id": "9da60638-5be8-4b5f-a721-2c6627aeaf0c",
        "outputId": "0a239cc9-f352-4292-bc7b-9d424717c0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                    inputs.input  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f  When did langchain first announce the hub?   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291             What is the langsmith cookbook?   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2                 When was Llama-v2 released?   \n",
              "2073dc30-4796-4b5e-8171-809d60476535                           What's LangSmith?   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea                          What is LangChain?   \n",
              "\n",
              "                                                                       reference.output  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f                                  September 5, 2023   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291  The langsmith cookbook is a github repository ...   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2                                      July 18, 2023   \n",
              "2073dc30-4796-4b5e-8171-809d60476535  LangSmith is a unified platform for debugging,...   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea  LangChain is an open-source framework for buil...   \n",
              "\n",
              "                                                                             error  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f  _get_url() https://links.duckduckgo.com/d.js   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291  _get_url() https://links.duckduckgo.com/d.js   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2  _get_url() https://links.duckduckgo.com/d.js   \n",
              "2073dc30-4796-4b5e-8171-809d60476535                                          None   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea  _get_url() https://links.duckduckgo.com/d.js   \n",
              "\n",
              "                                      execution_time  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f        4.492535   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291        4.619183   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2        4.235076   \n",
              "2073dc30-4796-4b5e-8171-809d60476535        6.659066   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea        4.271032   \n",
              "\n",
              "                                                                    run_id  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f  43e60662-5e30-41a9-8a8e-130a1a1f624d   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291  5c505aff-e25e-4d6d-b2c0-398121626423   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2  91626df8-d1f9-4720-b0cc-6516e9f33edc   \n",
              "2073dc30-4796-4b5e-8171-809d60476535  e7871c37-77ef-44d6-94f3-63099a0e838b   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea  6c3ce297-df4c-4120-9721-8ac43733da42   \n",
              "\n",
              "                                          outputs.input  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f                NaN   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291                NaN   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2                NaN   \n",
              "2073dc30-4796-4b5e-8171-809d60476535  What's LangSmith?   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea                NaN   \n",
              "\n",
              "                                                                         outputs.output  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f                                                NaN   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291                                                NaN   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2                                                NaN   \n",
              "2073dc30-4796-4b5e-8171-809d60476535  LangSmith is a platform for developing and eva...   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea                                                NaN   \n",
              "\n",
              "                                      feedback.correctness  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f                   NaN   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291                   NaN   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2                   NaN   \n",
              "2073dc30-4796-4b5e-8171-809d60476535                   1.0   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea                   NaN   \n",
              "\n",
              "                                      feedback.embedding_cosine_distance  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f                                 NaN   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291                                 NaN   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2                                 NaN   \n",
              "2073dc30-4796-4b5e-8171-809d60476535                            0.053305   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea                                 NaN   \n",
              "\n",
              "                                      feedback.helpfulness  \\\n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f                   NaN   \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291                   NaN   \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2                   NaN   \n",
              "2073dc30-4796-4b5e-8171-809d60476535                   1.0   \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea                   NaN   \n",
              "\n",
              "                                      feedback.score_string:accuracy  \n",
              "c2564f23-cd21-4475-9236-3e1796ab0c3f                             NaN  \n",
              "09f2f6cb-cd87-4b22-9e04-3db860ece291                             NaN  \n",
              "61ad4fa1-7142-492d-8108-55f08141d7d2                             NaN  \n",
              "2073dc30-4796-4b5e-8171-809d60476535                             0.7  \n",
              "68217b90-657a-4b90-b3ef-639aa77aefea                             NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec17dc50-1dd4-46e3-8075-d55561ef0a91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.input</th>\n",
              "      <th>reference.output</th>\n",
              "      <th>error</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>run_id</th>\n",
              "      <th>outputs.input</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.embedding_cosine_distance</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.score_string:accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>c2564f23-cd21-4475-9236-3e1796ab0c3f</th>\n",
              "      <td>When did langchain first announce the hub?</td>\n",
              "      <td>September 5, 2023</td>\n",
              "      <td>_get_url() https://links.duckduckgo.com/d.js</td>\n",
              "      <td>4.492535</td>\n",
              "      <td>43e60662-5e30-41a9-8a8e-130a1a1f624d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09f2f6cb-cd87-4b22-9e04-3db860ece291</th>\n",
              "      <td>What is the langsmith cookbook?</td>\n",
              "      <td>The langsmith cookbook is a github repository ...</td>\n",
              "      <td>_get_url() https://links.duckduckgo.com/d.js</td>\n",
              "      <td>4.619183</td>\n",
              "      <td>5c505aff-e25e-4d6d-b2c0-398121626423</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61ad4fa1-7142-492d-8108-55f08141d7d2</th>\n",
              "      <td>When was Llama-v2 released?</td>\n",
              "      <td>July 18, 2023</td>\n",
              "      <td>_get_url() https://links.duckduckgo.com/d.js</td>\n",
              "      <td>4.235076</td>\n",
              "      <td>91626df8-d1f9-4720-b0cc-6516e9f33edc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2073dc30-4796-4b5e-8171-809d60476535</th>\n",
              "      <td>What's LangSmith?</td>\n",
              "      <td>LangSmith is a unified platform for debugging,...</td>\n",
              "      <td>None</td>\n",
              "      <td>6.659066</td>\n",
              "      <td>e7871c37-77ef-44d6-94f3-63099a0e838b</td>\n",
              "      <td>What's LangSmith?</td>\n",
              "      <td>LangSmith is a platform for developing and eva...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.053305</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68217b90-657a-4b90-b3ef-639aa77aefea</th>\n",
              "      <td>What is LangChain?</td>\n",
              "      <td>LangChain is an open-source framework for buil...</td>\n",
              "      <td>_get_url() https://links.duckduckgo.com/d.js</td>\n",
              "      <td>4.271032</td>\n",
              "      <td>6c3ce297-df4c-4120-9721-8ac43733da42</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec17dc50-1dd4-46e3-8075-d55561ef0a91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec17dc50-1dd4-46e3-8075-d55561ef0a91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec17dc50-1dd4-46e3-8075-d55561ef0a91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0720da53-c3cf-4c6d-a81b-0013263ec72d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0720da53-c3cf-4c6d-a81b-0013263ec72d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0720da53-c3cf-4c6d-a81b-0013263ec72d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "chain_results.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13aad317-73ff-46a7-a5a0-60b5b5295f02",
      "metadata": {
        "id": "13aad317-73ff-46a7-a5a0-60b5b5295f02"
      },
      "source": [
        "### (Optional) Compare to another prompt\n",
        "\n",
        "Now that we have our test run results, we can make changes to our agent and benchmark them. Let's try this again with a different prompt and see the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5eeb023f-ded2-4d0f-b910-2a57d9675853",
      "metadata": {
        "id": "5eeb023f-ded2-4d0f-b910-2a57d9675853",
        "outputId": "ff5870b3-d974-42f2-de37-277f1053dc9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'runnable-agent-test-39f3bbd0-70daa046' at:\n",
            "https://smith.langchain.com/o/0f7461cf-206f-5c85-aa8d-48c6c48bafc5/datasets/febb8a4c-8d98-464b-bc92-dc897d5c9014/compare?selectedSessions=71fb7f6e-5605-4456-be69-2cfb16afbd6e\n",
            "\n",
            "View all tests for Dataset agent-qa-70daa046 at:\n",
            "https://smith.langchain.com/o/0f7461cf-206f-5c85-aa8d-48c6c48bafc5/datasets/febb8a4c-8d98-464b-bc92-dc897d5c9014\n",
            "[>                                                 ] 0/5"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:Chain failed for example 68217b90-657a-4b90-b3ef-639aa77aefea with inputs {'input': 'What is LangChain?'}\n",
            "Error Type: RateLimitException, Message: _get_url() https://links.duckduckgo.com/d.js\n",
            "WARNING:langchain.smith.evaluation.runner_utils:Chain failed for example 09f2f6cb-cd87-4b22-9e04-3db860ece291 with inputs {'input': 'What is the langsmith cookbook?'}\n",
            "Error Type: RateLimitException, Message: _get_url() https://links.duckduckgo.com/d.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------->                                        ] 1/5\r[------------------->                              ] 2/5"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:Chain failed for example 61ad4fa1-7142-492d-8108-55f08141d7d2 with inputs {'input': 'When was Llama-v2 released?'}\n",
            "Error Type: RateLimitException, Message: _get_url() https://links.duckduckgo.com/d.js\n",
            "WARNING:langchain.smith.evaluation.runner_utils:Chain failed for example 2073dc30-4796-4b5e-8171-809d60476535 with inputs {'input': \"What's LangSmith?\"}\n",
            "Error Type: RateLimitException, Message: _get_url() https://links.duckduckgo.com/d.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[------------------------------------------------->] 5/5\n",
            " Experiment Results:\n",
            "        feedback.correctness  feedback.embedding_cosine_distance  feedback.helpfulness  feedback.score_string:accuracy                                         error  execution_time                                run_id\n",
            "count                   1.00                                1.00                  1.00                            1.00                                             4            5.00                                     5\n",
            "unique                   NaN                                 NaN                   NaN                             NaN                                             4             NaN                                     5\n",
            "top                      NaN                                 NaN                   NaN                             NaN  _get_url() https://links.duckduckgo.com/d.js             NaN  d8eef4cc-c78b-439c-87f8-0f76cbf776cd\n",
            "freq                     NaN                                 NaN                   NaN                             NaN                                             1             NaN                                     1\n",
            "mean                    0.00                                0.27                  0.00                            0.50                                           NaN            3.18                                   NaN\n",
            "std                      NaN                                 NaN                   NaN                             NaN                                           NaN            1.03                                   NaN\n",
            "min                     0.00                                0.27                  0.00                            0.50                                           NaN            2.56                                   NaN\n",
            "25%                     0.00                                0.27                  0.00                            0.50                                           NaN            2.64                                   NaN\n",
            "50%                     0.00                                0.27                  0.00                            0.50                                           NaN            2.82                                   NaN\n",
            "75%                     0.00                                0.27                  0.00                            0.50                                           NaN            2.90                                   NaN\n",
            "max                     0.00                                0.27                  0.00                            0.50                                           NaN            5.00                                   NaN\n"
          ]
        }
      ],
      "source": [
        "candidate_prompt = hub.pull(\"wfh/langsmith-agent-prompt:39f3bbd0\")\n",
        "\n",
        "chain_results = run_on_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    llm_or_chain_factory=functools.partial(agent_factory, prompt=candidate_prompt),\n",
        "    evaluation=evaluation_config,\n",
        "    verbose=True,\n",
        "    client=client,\n",
        "    project_name=f\"runnable-agent-test-39f3bbd0-{unique_id}\",\n",
        "    tags=[\n",
        "        \"testing-notebook\",\n",
        "        \"prompt:39f3bbd0\",\n",
        "    ],  # Optional, adds a tag to the resulting chain runs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "591c819e-9932-45cf-adab-63727dd49559",
      "metadata": {
        "id": "591c819e-9932-45cf-adab-63727dd49559"
      },
      "source": [
        "## Exporting datasets and runs\n",
        "\n",
        "LangSmith lets you export data to common formats such as CSV or JSONL directly in the web app. You can also use the client to fetch runs for further analysis, to store in your own database, or to share with others. Let's fetch the run traces from the evaluation run.\n",
        "\n",
        "**Note: It may be a few moments before all the runs are accessible.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "33bfefde-d1bb-4f50-9f7a-fd572ee76820",
      "metadata": {
        "tags": [],
        "id": "33bfefde-d1bb-4f50-9f7a-fd572ee76820"
      },
      "outputs": [],
      "source": [
        "runs = client.list_runs(project_name=chain_results[\"project_name\"], execution_order=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6595c888-1f5c-4ae3-9390-0a559f5575d1",
      "metadata": {
        "tags": [],
        "id": "6595c888-1f5c-4ae3-9390-0a559f5575d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44c055f-792b-4e27-9de5-354b464deb86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'correctness': {'n': 1, 'avg': 0.0},\n",
              " 'embedding_cosine_distance': {'n': 1, 'avg': 0.2726},\n",
              " 'helpfulness': {'n': 1, 'avg': 0.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# After some time, these will be populated.\n",
        "client.read_project(project_name=chain_results[\"project_name\"]).feedback_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2646f0fb-81d4-43ce-8a9b-54b8e19841e2",
      "metadata": {
        "tags": [],
        "id": "2646f0fb-81d4-43ce-8a9b-54b8e19841e2"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You have successfully traced and evaluated an agent using LangSmith!\n",
        "\n",
        "This was a quick guide to get started, but there are many more ways to use LangSmith to speed up your developer flow and produce better results.\n",
        "\n",
        "For more information on how you can get the most out of LangSmith, check out [LangSmith documentation](https://docs.smith.langchain.com/), and please reach out with questions, feature requests, or feedback at [support@langchain.dev](mailto:support@langchain.dev)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}